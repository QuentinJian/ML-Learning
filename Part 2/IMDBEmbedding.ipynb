{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "from keras.layers import Embedding\r\n",
    "embedding_layer = Embedding(1000, 64)\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from keras.datasets import imdb\r\n",
    "from keras import preprocessing\r\n",
    "\r\n",
    "max_features = 10000\r\n",
    "maxlen = 20\r\n",
    "\r\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\r\n",
    "\r\n",
    "print(x_train.shape)\r\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen=maxlen)\r\n",
    "print(x_train.shape)\r\n",
    "\r\n",
    "print(x_train[0])\r\n",
    "\r\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen=maxlen)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "<__array_function__ internals>:5: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "C:\\Users\\clare\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:159: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_train, y_train = np.array(xs[:idx]), np.array(labels[:idx])\n",
      "C:\\Users\\clare\\anaconda3\\envs\\ml\\lib\\site-packages\\tensorflow\\python\\keras\\datasets\\imdb.py:160: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  x_test, y_test = np.array(xs[idx:]), np.array(labels[idx:])\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(25000,)\n",
      "(25000, 100)\n",
      "[1415   33    6   22   12  215   28   77   52    5   14  407   16   82\n",
      "    2    8    4  107  117 5952   15  256    4    2    7 3766    5  723\n",
      "   36   71   43  530  476   26  400  317   46    7    4    2 1029   13\n",
      "  104   88    4  381   15  297   98   32 2071   56   26  141    6  194\n",
      " 7486   18    4  226   22   21  134  476   26  480    5  144   30 5535\n",
      "   18   51   36   28  224   92   25  104    4  226   65   16   38 1334\n",
      "   88   12   16  283    5   16 4472  113  103   32   15   16 5345   19\n",
      "  178   32]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "from keras.models import Sequential\r\n",
    "from keras.layers import Flatten, Embedding, Dense\r\n",
    "\r\n",
    "model = Sequential()\r\n",
    "model.add(Embedding(10000, 8, input_length=maxlen))\r\n",
    "\r\n",
    "model.add(Flatten())\r\n",
    "\r\n",
    "model.add(Dense(1, activation='sigmoid'))\r\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\r\n",
    "model.summary()\r\n",
    "\r\n",
    "history = model.fit(x_train, y_train,\r\n",
    "                    epochs=10,\r\n",
    "                    batch_size=32,\r\n",
    "                    validation_split=0.2)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 100, 8)            80000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 801       \n",
      "=================================================================\n",
      "Total params: 80,801\n",
      "Trainable params: 80,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.6338 - acc: 0.6561 - val_loss: 0.4895 - val_acc: 0.7922\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.3790 - acc: 0.8494 - val_loss: 0.3533 - val_acc: 0.8476\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2900 - acc: 0.8813 - val_loss: 0.3307 - val_acc: 0.8544\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2520 - acc: 0.8975 - val_loss: 0.3243 - val_acc: 0.8610\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2263 - acc: 0.9111 - val_loss: 0.3278 - val_acc: 0.8586\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.2063 - acc: 0.9194 - val_loss: 0.3301 - val_acc: 0.8610\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.1873 - acc: 0.9296 - val_loss: 0.3389 - val_acc: 0.8570\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.1693 - acc: 0.9383 - val_loss: 0.3483 - val_acc: 0.8554\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.1520 - acc: 0.9460 - val_loss: 0.3689 - val_acc: 0.8512\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 2s 3ms/step - loss: 0.1360 - acc: 0.9527 - val_loss: 0.3664 - val_acc: 0.8528\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}