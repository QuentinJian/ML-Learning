{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import os\r\n",
    "\r\n",
    "imdb_dir = r'C:/Users/clare\\Documents/aclImdb'\r\n",
    "train_dir = os.path.join(imdb_dir, 'train')\r\n",
    "\r\n",
    "labels = []\r\n",
    "texts = []\r\n",
    "\r\n",
    "for label_type in ['neg', 'pos']:\r\n",
    "    dir_name = os.path.join(train_dir, label_type)\r\n",
    "    for fname in os.listdir(dir_name):\r\n",
    "        if fname[-4:] == \".txt\":\r\n",
    "            f = open(os.path.join(dir_name, fname), encoding='utf8')\r\n",
    "            texts.append(f.read())\r\n",
    "            f.close()\r\n",
    "            if label_type == 'neg':\r\n",
    "                labels.append(0)\r\n",
    "            else:\r\n",
    "                labels.append(1)\r\n",
    "\r\n",
    "print(len(texts))"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "25000\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from keras.preprocessing.text import Tokenizer\r\n",
    "from keras.preprocessing.sequence import pad_sequences\r\n",
    "import numpy as np\r\n",
    "\r\n",
    "maxlen = 100\r\n",
    "training_samples = 200\r\n",
    "validation_samples = 10000\r\n",
    "max_words = 10000\r\n",
    "\r\n",
    "tokenizer = Tokenizer(num_words=max_words)\r\n",
    "tokenizer.fit_on_texts(texts)\r\n",
    "sequences = tokenizer.texts_to_sequences(texts)\r\n",
    "\r\n",
    "word_index = tokenizer.word_index\r\n",
    "\r\n",
    "print('共用了 %s 個 token 字詞.' % len(word_index))\r\n",
    "\r\n",
    "data = pad_sequences(sequences, maxlen=maxlen)\r\n",
    "labels = np.asarray(labels)\r\n",
    "\r\n",
    "print(\"資料張量：\", data.shape)\r\n",
    "print(\"標籤張量：\", labels.shape)\r\n",
    "\r\n",
    "indices = np.arange(data.shape[0])\r\n",
    "np.random.shuffle(indices)\r\n",
    "data = data[indices]\r\n",
    "labels = labels[indices]\r\n",
    "\r\n",
    "x_train = data[:training_samples]\r\n",
    "y_train = labels[:training_samples]\r\n",
    "x_val = data[training_samples: training_samples + validation_samples]\r\n",
    "y_val = labels[training_samples: training_samples + validation_samples]"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}