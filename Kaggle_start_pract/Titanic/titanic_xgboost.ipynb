{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import pandas as pd\r\n",
    "\r\n",
    "train = pd.read_csv('train.csv')\r\n",
    "test = pd.read_csv('test.csv')\r\n",
    "\r\n",
    "train_x = train.drop(['Survived'], axis=1)\r\n",
    "train_y = train['Survived']\r\n",
    "\r\n",
    "test_x = test.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "from sklearn.preprocessing import LabelEncoder\r\n",
    "\r\n",
    "train_x = train_x.drop(['PassengerId'], axis=1)\r\n",
    "test_x = test_x.drop(['PassengerId'], axis=1)\r\n",
    "\r\n",
    "train_x = train_x.drop(['Name', 'Ticket', 'Cabin'], axis=1)\r\n",
    "test_x = test_x.drop(['Name', 'Ticket', 'Cabin'], axis=1)\r\n",
    "\r\n",
    "for c in ['Sex', 'Embarked']:\r\n",
    "    le = LabelEncoder()\r\n",
    "    le.fit(train_x[c].fillna('NA'))\r\n",
    "\r\n",
    "    train_x[c] = le.transform(train_x[c].fillna('NA'))\r\n",
    "    test_x[c] = le.transform(test_x[c].fillna('NA'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "from xgboost import XGBClassifier\r\n",
    "\r\n",
    "model = XGBClassifier(n_estimators=20, random_state=71)\r\n",
    "model.fit(train_x, train_y)\r\n",
    "\r\n",
    "pred = model.predict_proba(test_x)[:, 1]\r\n",
    "\r\n",
    "pred_label = np.where(pred > 0.5, 1, 0)\r\n",
    "\r\n",
    "submission = pd.DataFrame({'PassengerId' : test['PassengerId'], 'Survived' : pred_label})\r\n",
    "submission.to_csv(\"submission_first.csv\", index=False)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[14:07:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\clare\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "from sklearn.metrics import log_loss, accuracy_score\r\n",
    "from sklearn.model_selection import KFold\r\n",
    "\r\n",
    "scores_accuracy = []\r\n",
    "scores_logloss = []\r\n",
    "\r\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=71)\r\n",
    "\r\n",
    "for tr_idx, va_idx in kf.split(train_x):\r\n",
    "    tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\r\n",
    "    tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\r\n",
    "\r\n",
    "    model = XGBClassifier(n_estimators=20, random_state=71)\r\n",
    "    model.fit(tr_x, tr_y)\r\n",
    "\r\n",
    "    va_pred = model.predict_proba(va_x)[:, 1]\r\n",
    "\r\n",
    "    logloss = log_loss(va_y, va_pred)\r\n",
    "    accuracy = accuracy_score(va_y, va_pred > 0.5)\r\n",
    "\r\n",
    "    scores_logloss.append(logloss)\r\n",
    "    scores_accuracy.append(accuracy)\r\n",
    "\r\n",
    "\r\n",
    "logloss = np.mean(scores_logloss)\r\n",
    "accuracy = np.mean(scores_accuracy)\r\n",
    "print(f'logloss: {logloss:.4f}, accuracy: {accuracy:.4f}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[14:07:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:07:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:07:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[14:07:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "logloss: 0.4384, accuracy: 0.8182\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\clare\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\clare\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Users\\clare\\anaconda3\\envs\\ml\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "import itertools\r\n",
    "\r\n",
    "param_space = {\r\n",
    "    'maxdepth' : [3, 5, 7],\r\n",
    "    'min_child_weight' : [1.0, 2.0, 4.0]\r\n",
    "}\r\n",
    "param_combinations = itertools.product(param_space['maxdepth'], param_space['min_child_weight'])\r\n",
    "\r\n",
    "params = []\r\n",
    "scores = []\r\n",
    "\r\n",
    "for max_depth, min_child_weight in param_combinations:\r\n",
    "    score_folds = []\r\n",
    "\r\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=123456)\r\n",
    "    for tr_idx, va_idx, in kf.split(train_x):\r\n",
    "        tr_x, va_x = train_x.iloc[tr_idx], train_x.iloc[va_idx]\r\n",
    "        tr_y, va_y = train_y.iloc[tr_idx], train_y.iloc[va_idx]\r\n",
    "\r\n",
    "        model = XGBClassifier(n_estimators=20, random_state=71, verbosity=0,max_depth=max_depth, min_child_weight=min_child_weight, use_label_encoder=False)\r\n",
    "        model.fit(tr_x, tr_y)\r\n",
    "\r\n",
    "        va_pred = model.predict_proba(va_x)[:, 1]\r\n",
    "        logloss = log_loss(va_y, va_pred)\r\n",
    "        score_folds.append(logloss)\r\n",
    "    \r\n",
    "    score_mean = np.mean(score_folds)\r\n",
    "    params.append((max_depth, min_child_weight))\r\n",
    "    scores.append(score_mean)\r\n",
    "\r\n",
    "best_idx = np.argsort(scores)[0]\r\n",
    "best_param = params[best_idx]\r\n",
    "print(f'max_depth: {best_param[0]}, min_child_weight: {best_param[1]}')"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "max_depth: 3, min_child_weight: 2.0\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\r\n",
    "\r\n",
    "train_x2 = train.drop(['Survived'], axis=1)\r\n",
    "test_x2 = test.copy()\r\n",
    "\r\n",
    "train_x2 = train_x2.drop(['PassengerId'], axis=1)\r\n",
    "test_x2 = test_x2.drop(['PassengerId'], axis=1)\r\n",
    "\r\n",
    "train_x2 = train_x2.drop(['Name', 'Ticket', 'Cabin'], axis=1)\r\n",
    "test_x2 = test_x2.drop(['Name', 'Ticket', 'Cabin'], axis=1)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.10",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.10 64-bit ('ml': conda)"
  },
  "interpreter": {
   "hash": "fe4a84b179b939cdf3b8e898a4b0079c01494022728fa66163902f78daf84c10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}